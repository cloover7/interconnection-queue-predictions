{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ER131 Final Project Template\n",
    "Fall 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interconnection Queues\n",
    " \n",
    "1. Molly Ho:\n",
    "2. Angela Shao:\n",
    "3. Erin Yang:\n",
    "\n",
    "In this cell, replace the text above with your project title.  Then give an alphabetical (by last name) list of student group members.  Beside each student's name, provide a description of each student's contribution to the project, and an estimate of the number of hours each student put into the effort.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background information (delete this markdown cell in your final submission)\n",
    "\n",
    "## How to use this notebook: \n",
    "* Follow the format and sequencing of sections\n",
    "* Edit the markdown cells to be specific to your project.\n",
    "* Put the code you use to accomplish the tasks of each section in between each markdown cell.\n",
    "* Delete this cell before you hand in the notebook\n",
    "* As with homeworks, you'll hand in a `.ipynb` file and an `.html` file; we'll also ask you to make your data available. \n",
    "\n",
    "## Basic Project Requirements:\n",
    "\n",
    "This notebook is the template for your semester project.  Each markdown cell provides instructions on what to do in order to complete a successful project.  The cell you're reading right now is the only one you can delete from what you eventually hand in.  For the other cells:\n",
    "1. You may replace the instructions in each cell with your own work but do not edit the cell titles (with the exception of the project title, above).  \n",
    "2. Follow the instructions in each section carefully.  For some sections you will enter only markdown text in the existing cells. For other sections, you'll accompany the markdown cells with additional code cells, and perhaps more markdown, before moving on to the next section.  \n",
    "\n",
    "**Number of prediction questions:**  The number of prediction questions must be greater than or equal to $N_s-1$, the number of students in the team minus one.  (Two prediction questions are different if they use different target variables.) For example, a 3 person team would need to examine $3-1 = 2$ questions.  Questions should be related, but have distinct work efforts, interpretation and analysis. An example: for land use regression, you could have a core prediction question (what is pollution concentration on a fine spatial scale), a supporting question that explore how the degree of spatial aggregation influences prediction quality, plus a prediction model that explores *temporal* prediction at one point in space.  There is a lot of flexibility here; if you have any doubt about whether your questions are distinct, consult with the instructors.\n",
    "\n",
    "**Number of models**: For each prediction question (target variable) you must train and evaluate the performance of three different machine learning models. E.g. for regression, you could do OLS, lasso, and regression tree.\n",
    "\n",
    "**Data requirements**:  Projects must use data from a minimum of three different sources for groups of four, or two data sources for groups of less than four.  You must *merge* at least two data sets. </font>\n",
    "\n",
    "**Group composition:** \n",
    "* Groups must be all undergraduate or all graduate students. That is, no mixing of graduate and undergraduate students.\n",
    "* Undergraduate groups must be four people; Graduate student groups can be smaller with permission.   \n",
    "* We recommend that you have a mix of students from across colleges / majors (e.g. CNR, CS, Data Science, Engineering, L&S).   \n",
    "\n",
    "**Grading**.  You'll see point allocations listed in each of the section titles below.  In addition, there are other categories for points: \n",
    "1. Abstract (5 points).\n",
    "2. Project backround (5 points).\n",
    "3. Project objective (5 points).\n",
    "4. Data description (5 points).\n",
    "5. Data cleaning (10 points).\n",
    "6. EDA (10 points).\n",
    "7. Forecasting and Prediction Modeling (25 points).\n",
    "8. Interpretation and Conclusions (20 points).\n",
    "2. Visualization (10 points).  Plots should be well organized, legible, labelled, and well-suited for the question they are being used to answer or explore. \n",
    "2. Clarity (5 points). Note that clarity also supports points elsewhere, because if we can't understand what you're explaining, we'll assume you didn't understand what you were doing and give points accordingly!  \n",
    "\n",
    "For each Section or Category, we will give points according to the following percentage scale:\n",
    "1. More than 90%:  work that is free of anything but superficial mistakes, and demonstrates creativity and / or a very deep understanding of what you are doing.\n",
    "2. 80-90%: work without fundamental errors and demonstrates a basic understanding of what you're doing.\n",
    "3. 60-80%: work with fundamental flaws in the analysis and / or conveys that you do not understand the basics of the work you are trying to do.\n",
    "4. Below 60%: Work that is severely lacking or incomplete.  \n",
    "\n",
    "Note that we distinguish *mistakes* from *\"my idea didn't work\"*.  Sometimes you don't know if you can actually do the thing you're trying to do and as you dig in you find that you can't.  That doesn't necessarily mean you made a mistake; it might just mean you needed more information.  We'll still give high marks to ambitious projects that \"fail\" at their stated objective, as long as that objective was clear and you demonstrate an understanding of what you were doing and why it didn't work.\n",
    "\n",
    "**Starting data**: To help contain your scope early on, we are providing you with several data sets to start your journey with.  Please go to the `project` in datahub; each folder contains a different starter notebook and data. \n",
    "\n",
    "**Additional suggested data sets**: See the last markdown cell of this notebook for some suggestions.\n",
    "\n",
    "**A few other guiding remarks**\n",
    "* The notebook should tell the story of your modeling and learning experience. We’ve set up the outline to help you do this.  Think about the overall arc of your project and use the notebook to explain the most important aspects of your thinking and what you’ve learned.  Make time to take a step back from the individual parts of the notebook to think about how it flows as a complete document.\n",
    "* Markdown cells, not code cells, are where you convey your thinking and methodology. \n",
    "* We won’t read your code cells to understand your thinking or methods\n",
    "* We will only use your code cells to verify your workflow\n",
    "* Less is more when it comes to code output and visualizations. Any output should serve a purpose for the reader of the notebook, and you should make that purpose clear in your markdown cells.  For example: \n",
    "* Don’t display every line of a dataframe; use `.head()` or printouts of specific parts of a dataframe judiciously. Display contents of a dataframe when you want to show the reader something specific, and explain your thinking in a markdown cell.\n",
    "* Use visualizations to tell your story, but make sure you explain in markdown cells what’s important about your visualizations. If you can’t tell the reader what’s important about the visualization, leave it out!\n",
    "* Suppress output of functions unless it is crucial to explain your thinking and demonstrate your workflow.\n",
    "* Generally, the notebook should not contain copious amounts of data, function outputs, plots. Think of your notebook as a giant function with a `verbose` argument…I want verbose = FALSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract (5 points)\n",
    "Although this section comes first, you'll write it last.  It should be a ~250 word summary of your project.  1/3rd of the abstract should provide background, 1/3rd should explain what you did, and 1/3rd should explain what you learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Background (5 points)\n",
    "In this section you will describe relevant background for your project.  It should give enough information that a non-expert can understand in detail the history and / or context of the system or setting you wish to study, the need for quantitative analysis, and, broadly, what impact a quantitative analyses could have on the system.  Shoot for 500 words here.
    The Interconnection Queue is a waitlist of proposed electricity generation projects, ranging from solar to gas to coal, that are seeking to connect to the electric grid. Each project must undergo a series of reviews before becoming operational. However, the queue is greatly backlogged, with many projects taking years from when they first join the queue to when they become operational. Thus, the queue has become a bottleneck, reducing the possible addition of much new generation capacity to the grid. 
    In recent years, there have been reforms put in place such as those from the Federal Energy Regulatory Commission (FERC) Order 2023 which sought to streamline the interconnection queue process. One such reform addresses interconnection queue backlog through a "first-ready, first-served" cluster study process, which allowed interceonncetion requests that are equally queued and of equal study priority to be studied in groups. Increased financial commitments and readiness requirements to enter and proceed in the queue were put in place as well. Only time will tell whether or not the reforms prove successful in reducing the backlog and making the process more efficient. 
    In the meantime, there is a need for quantitative analysis that would be helpful both for projects currently in the queue and ones that are considering entering it. This includes creating models that predict the likelihood a project will get accepted within 5 years and what their POI cost per kilowatt would be. 
    This type of quantitative analyses will help projects determine whether they should stay or withdraw, or even join the queue in the first place, based on information regarding potential wait time on the queue and POI cost if accepted. As a result, the system will also become more efficient as projects that end up withdrawing later on in the queue process will not be there to contribute to the long wait times or trigger the consequences of withdrawaal such as a need for restudies and reevaluation of cost allocations in cluster studies. 
  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Objective (5 points)\n",
    "In this section you will pose the central objective or objectives for your semester project.  Objectives should be extremely clear, well-defined and clearly cast as forecasting problems.  \n",
    "\n",
    "Some example questions: \n",
    "1. *\"The purpose of this project is to train and evaluate different models to predict soil heavy metal contamination levels across the state of Louisiana, using a variety of features drawn from EPA, the US Census, and NAICS databases.\"* or\n",
    "2. *\"The purpose of this project is to train and evaluate different models to predict 1-minute generation from a UCSD solar PV site, up to 2 hours into the future, using historical data as well as basic weather forecast variables.*\" or\n",
    "3. *\"The purpose of this project is to forecast daily emergency room visits for cardiac problems in 4 major US cities, using a majority of features including air quality forecasts, weather forecasts and seasonal variables.\"*\n",
    "\n",
    "You should reflect here on why it's important to answer these questions.  In most cases this will mean that you'll frame the answers to your questions as informing one or more *resource allocation* problems.  If you have done a good job of providing project background (in the cell above) then this reflection will be short and easy to write.\n",
    "\n",
    "**Comment on novelty:** You may find it hard to identify a project question that has *never* been answered before.  It's ok if you take inspiration from existing analyses.  However you shouldn't exactly reproduce someone else's analysis.  If you take inspiration from another analyses, you should still use different models, different data, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data Description (5 points)\n",
    "Here you will provide an initial description of your data sets, including:\n",
    "1. The origins of your data.  Where did you get the data?  How were the data collected from the original sources?  You must provide enough information for the reader to be able to access the data themselves.  \n",
    "2. The structure, granularity, scope, temporality and faithfulness (SGSTF) of your data.  To discuss these attributes you should load the data into one or more data frames (so you'll start building code cells for the first time).  At a minimum, use some basic methods (`.head`, `.loc`, and so on) to provide support for the descriptions you provide for SGSTF. \n",
    "3. You should also describe which data fields you will use as your target variables, and which you will use as features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning (10 points)\n",
    "In this section you will walk through the data cleaning and merging process.  Explain how you make decisions to clean and merge the data.  Explain how you convince yourself that the data don't contain problems that will limit your ability to produce a meaningful analysis from them.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary and Exploratory Data Analysis (10 points)\n",
    "\n",
    "In this section you should provide a tour through some of the basic trends and patterns in your data.  This includes providing initial plots to summarize the data, such as box plots, histograms, trends over time, scatter plots relating one variable or another.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting and Prediction Modeling (25 points)\n",
    "\n",
    "This section is where the rubber meets the road.  In it you must:\n",
    "1. Explore at least 3 prediction modeling approaches for each prediction question, ranging from the simple (e.g. linear regression, KNN) to the complex (e.g. SVM, random forests, Lasso).  \n",
    "2. Motivate all your modeling decisions.  This includes parameter choices (e.g., how many folds in k-fold cross validation, what time window you use for averaging your data) as well as model form (e.g., If you use regression trees, why?  If you include nonlinear features in a regression model, why?). \n",
    "1. Carefully describe your cross validation and model selection process.  You should partition your data into training and testing data sets.  The training data set is what you use for cross-validation (i.e. you sample from within it to create folds, etc.).  The testing data set is held to the very end of your efforts, and used to compare qualitatively different models (e.g. OLS vs random forests).\n",
    "4. Very carefully document your workflow.  We will be reading a lot of projects, so we need you to explain each basic step in your analysis.  \n",
    "5. Seek opportunities to write functions allow you to avoid doing things over and over, and that make your code more succinct and readable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Allocation and Conclusions (20 points)\n",
    "In this section you must relate your modeling and forecasting results to your original prediction question.  You must:\n",
    "1. Address a resource allocation question.  What do the answers mean? What advice would you give a decision maker on the basis of your results?  How might they allocate their resources differently with the results of your model?  Why should the reader care about your results?  *To get full marks you must provide both a qualitative and quantitative analysis.*\n",
    "2. Discuss caveats and / or reasons your results might be flawed.  No model is perfect, and understanding a model's imperfections is extremely important for the purpose of knowing how to interpret your results.  Often, we know the model output is wrong but we can assign a direction for its bias.  This helps to understand whether or not your answers are conservative.  \n",
    "\n",
    "Shoot for 500-1000 words for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ER 131 Data sources (delete this cell from your final project)\n",
    "Many of these links just take you to the main landing page for the data.  Note a number of these links also lead you to many different data sets.\n",
    "\n",
    "## Energy data\n",
    "1. [Integrated Circuit Analysis (ICA) load data from Pacific Gas & Electric (PG&E) company](https://www.pge.com/en/about/doing-business-with-pge/interconnections/distributed-resource-planning-data-and-maps.html)\n",
    "2. [Cool Climate -- spatially resolved energy and carbon emissions data](https://coolclimate.berkeley.edu/data)\n",
    "3. [Residential Energy Consumption Survey](https://www.eia.gov/consumption/residential/)\n",
    "4. [California Grid Operator market data](http://oasis.caiso.com/mrioasis/logon.do)\n",
    "5. [California Energy Commission data archives -- many different sources of data describing energy production and use in California](https://www.energy.ca.gov/data-reports)\n",
    "5. [Alternative fuels data center](https://afdc.energy.gov/)\n",
    "\n",
    "\n",
    "## Transportation data\n",
    "1. [California Air Resources Board’s Fleet Database](https://arb.ca.gov/emfac/fleet-db)\n",
    "2. [EV Charging Stations Source](https://www.energy.ca.gov/data-reports/energy-insights/zero-emission-vehicle-and-charger-statistics)\n",
    "3. [California vehicle fuel type counts by zip code (there are more years available)](https://www.dmv.ca.gov/portal/uploads/2020/04/MotorVehicleFuelTypes_ZipCode_102018.pdf)\n",
    "4. [Census Bureau means of transport](https://data.census.gov/cedsci/table?q=MEANS%20OF%20TRANSPORTATION%20TO%20WORK%20BY%20VEHICLES&tid=ACSDT1Y2018.B08141&hidePreview=false)\n",
    "4. [Census Bureau number of commuters](https://data.census.gov/cedsci/table?q=vehicle&g=0400000US06&tid=ACSDT1Y2019.B08015&hidePreview=true)\n",
    "4. [Atlas EV Hub](https://www.atlasevhub.com/)\n",
    "\n",
    "## Environmental data \n",
    "1. [Climate Model prediction data](https://cal-adapt.org/data/download/)\n",
    "2. [Water Quality Portal](https://www.waterqualitydata.us/wqp_description/)\n",
    "2. [Methane Plumes Derived from AVIRIS-NG over Point Sources across California, 2016-2017](https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1727)\n",
    "3. [EPA AirNow pollution data](https://www.epa.gov/outdoor-air-quality-data)\n",
    "\ta. [\"Pre-generated\" files here](https://aqs.epa.gov/aqsweb/airdata/download_files.html)\n",
    "4. [California Department of Water Resources Data Exchange Portal](http://cdec.water.ca.gov/index.html)\n",
    "5. [NOAA Climate data online](https://www.ncdc.noaa.gov/cdo-web/)\n",
    "5. [Methane emitting facilities from US Dept of Commerce](https://daac.ornl.gov/NACP/guides/NACP_Vista_CA_CH4_Inventory.html)\n",
    "4. [California Air Resources Board Emissions Inventory](https://ww3.arb.ca.gov/ei/maps/2017statemap/cntymap.htm)\n",
    "4. [Groundwater level measurements](https://data.cnra.ca.gov/dataset/periodic-groundwater-level-measurements)\n",
    "4. [California Enviroscreen -- includes pollution data by census block](https://oehha.ca.gov/calenviroscreen/report/calenviroscreen-30)\n",
    "5. [NEON Ecological Forecasting Challenge -- provides pre-processed target data for aquatic communities, carbon & water fluxes, tick populations, phenology, and beetle abundance](https://ecoforecast.org/efi-rcn-forecast-challenges/) *Ask Jessica if you have questions about using this data.*\n",
    "\n",
    "\n",
    "## Geographic and census data\n",
    "1. [California County boundaries](https://data.ca.gov/dataset/ca-geographic-boundaries/resource/b0007416-a325-4777-9295-368ea6b710e6)\n",
    "2. [Another CA county boundary dataset](https://catalog.data.gov/dataset/tiger-line-shapefile-2016-state-california-current-county-subdivision-state-based)\n",
    "3. [Census data](https://data.census.gov/cedsci/)\n",
    "\ta. Note these data can be accessed by an API.  [This](https://jtleider.github.io/censusdata/) codebase can help you access the API, which is [here](https://www.census.gov/data/developers.html)\n",
    "2. [Census Data from the US Census Bureau's ACS Demographic and Housing Estimates](https://data.census.gov/cedsci/table?q=United%20States&t=Counts,%20Estimates,%20and%20Projections%3AFamilies%20and%20Living%20Arrangements%3AHousing%3AHousing%20Units%3APopulation%20Total%3APopulations%20and%20People%3ARace%20and%20Ethnicity&g=0400000US06,06%24160000&tid=ACSDP5Y2018.DP05)\n",
    "3. [Labor Force Data](https://www.labormarketinfo.edd.ca.gov/data/industry-employment-and-unemployment-rates-for-counties.html)\n",
    "4. [USGS National Land Cover Database](https://www.mrlc.gov/data?f%5B0%5D=category%3Aland%20cover&f%5B1%5D=year%3A2016)\n",
    "4. [California Enviroscreen -- includes demographic data by census block, derived from census data](https://oehha.ca.gov/calenviroscreen/report/calenviroscreen-40)\n",
    "5. [USAID Demographic and Health Survey Data](https://dhsprogram.com/) \n",
    "\n",
    "## Other\n",
    "1. [USDA Cow Density Data](https://www.nass.usda.gov/Charts_and_Maps/Cattle/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
